{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\matplotlib\\cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from matplotlib import style\n",
    "import yahoo_finance as yahoo\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.finance import candlestick_ohlc\n",
    "from IPython.display import display, Math, Latex\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>DJIA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-03-01</th>\n",
       "      <td>112.4375</td>\n",
       "      <td>116.0000</td>\n",
       "      <td>11357.50977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>114.0000</td>\n",
       "      <td>112.0625</td>\n",
       "      <td>10997.92969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>112.9375</td>\n",
       "      <td>116.0000</td>\n",
       "      <td>11122.65039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-01</th>\n",
       "      <td>118.0000</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>11253.25977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-01</th>\n",
       "      <td>117.2500</td>\n",
       "      <td>113.5000</td>\n",
       "      <td>11522.55957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open     Close         DJIA\n",
       "Date                                       \n",
       "2000-03-01  112.4375  116.0000  11357.50977\n",
       "2000-04-01  114.0000  112.0625  10997.92969\n",
       "2000-05-01  112.9375  116.0000  11122.65039\n",
       "2000-06-01  118.0000  114.0000  11253.25977\n",
       "2000-07-01  117.2500  113.5000  11522.55957"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ibm/full_ibm.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "df.drop(['High', 'Adj Close', 'NDX', 'SP500', 'Volume', 'Low'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>ma7</th>\n",
       "      <th>ma30</th>\n",
       "      <th>std30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>19933.81055</td>\n",
       "      <td>167.161429</td>\n",
       "      <td>163.586334</td>\n",
       "      <td>3.291480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>166.979996</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>19945.03906</td>\n",
       "      <td>167.035714</td>\n",
       "      <td>163.782000</td>\n",
       "      <td>3.323355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>167.289993</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>19833.67969</td>\n",
       "      <td>166.958572</td>\n",
       "      <td>164.048000</td>\n",
       "      <td>3.178183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>166.020004</td>\n",
       "      <td>166.600006</td>\n",
       "      <td>19819.77930</td>\n",
       "      <td>166.947146</td>\n",
       "      <td>164.312334</td>\n",
       "      <td>3.042335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>166.440002</td>\n",
       "      <td>165.990005</td>\n",
       "      <td>19762.59961</td>\n",
       "      <td>166.717146</td>\n",
       "      <td>164.535667</td>\n",
       "      <td>2.903699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open       Close         DJIA         ma7        ma30  \\\n",
       "Date                                                                      \n",
       "2016-12-23  167.000000  166.710007  19933.81055  167.161429  163.586334   \n",
       "2016-12-27  166.979996  167.139999  19945.03906  167.035714  163.782000   \n",
       "2016-12-28  167.289993  166.190002  19833.67969  166.958572  164.048000   \n",
       "2016-12-29  166.020004  166.600006  19819.77930  166.947146  164.312334   \n",
       "2016-12-30  166.440002  165.990005  19762.59961  166.717146  164.535667   \n",
       "\n",
       "               std30  \n",
       "Date                  \n",
       "2016-12-23  3.291480  \n",
       "2016-12-27  3.323355  \n",
       "2016-12-28  3.178183  \n",
       "2016-12-29  3.042335  \n",
       "2016-12-30  2.903699  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ma7'] = df['Close'].rolling(window=7).mean()\n",
    "df['ma30'] = df['Close'].rolling(window=30).mean()\n",
    "df['std30'] = df['Close'].rolling(window=30).std()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4277, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>std30</th>\n",
       "      <th>ma7_1</th>\n",
       "      <th>ma7_2</th>\n",
       "      <th>ma7_3</th>\n",
       "      <th>ma7_4</th>\n",
       "      <th>ma30_1</th>\n",
       "      <th>ma30_2</th>\n",
       "      <th>ma30_3</th>\n",
       "      <th>ma30_4</th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>19933.81055</td>\n",
       "      <td>3.291480</td>\n",
       "      <td>161.771430</td>\n",
       "      <td>162.714286</td>\n",
       "      <td>158.895715</td>\n",
       "      <td>153.445711</td>\n",
       "      <td>155.241427</td>\n",
       "      <td>162.392857</td>\n",
       "      <td>157.824286</td>\n",
       "      <td>152.801428</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>167.330002</td>\n",
       "      <td>167.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>166.979996</td>\n",
       "      <td>19945.03906</td>\n",
       "      <td>3.323355</td>\n",
       "      <td>162.385716</td>\n",
       "      <td>162.975714</td>\n",
       "      <td>159.692858</td>\n",
       "      <td>153.605711</td>\n",
       "      <td>155.729998</td>\n",
       "      <td>161.992857</td>\n",
       "      <td>158.555714</td>\n",
       "      <td>152.949999</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>167.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>167.289993</td>\n",
       "      <td>19833.67969</td>\n",
       "      <td>3.178183</td>\n",
       "      <td>163.197143</td>\n",
       "      <td>162.554286</td>\n",
       "      <td>160.057144</td>\n",
       "      <td>154.667140</td>\n",
       "      <td>156.252856</td>\n",
       "      <td>161.764287</td>\n",
       "      <td>159.417143</td>\n",
       "      <td>153.077142</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>166.020004</td>\n",
       "      <td>19819.77930</td>\n",
       "      <td>3.042335</td>\n",
       "      <td>164.378570</td>\n",
       "      <td>162.175716</td>\n",
       "      <td>160.257143</td>\n",
       "      <td>155.998570</td>\n",
       "      <td>156.727142</td>\n",
       "      <td>161.705715</td>\n",
       "      <td>159.904286</td>\n",
       "      <td>153.242857</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>166.710007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>166.440002</td>\n",
       "      <td>19762.59961</td>\n",
       "      <td>2.903699</td>\n",
       "      <td>165.617142</td>\n",
       "      <td>161.870001</td>\n",
       "      <td>160.795713</td>\n",
       "      <td>156.832857</td>\n",
       "      <td>156.941428</td>\n",
       "      <td>161.414285</td>\n",
       "      <td>160.482858</td>\n",
       "      <td>153.197141</td>\n",
       "      <td>166.600006</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>167.139999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open         DJIA     std30       ma7_1       ma7_2  \\\n",
       "Date                                                                    \n",
       "2016-12-23  167.000000  19933.81055  3.291480  161.771430  162.714286   \n",
       "2016-12-27  166.979996  19945.03906  3.323355  162.385716  162.975714   \n",
       "2016-12-28  167.289993  19833.67969  3.178183  163.197143  162.554286   \n",
       "2016-12-29  166.020004  19819.77930  3.042335  164.378570  162.175716   \n",
       "2016-12-30  166.440002  19762.59961  2.903699  165.617142  161.870001   \n",
       "\n",
       "                 ma7_3       ma7_4      ma30_1      ma30_2      ma30_3  \\\n",
       "Date                                                                     \n",
       "2016-12-23  158.895715  153.445711  155.241427  162.392857  157.824286   \n",
       "2016-12-27  159.692858  153.605711  155.729998  161.992857  158.555714   \n",
       "2016-12-28  160.057144  154.667140  156.252856  161.764287  159.417143   \n",
       "2016-12-29  160.257143  155.998570  156.727142  161.705715  159.904286   \n",
       "2016-12-30  160.795713  156.832857  156.941428  161.414285  160.482858   \n",
       "\n",
       "                ma30_4     Close_1     Close_2     Close_3  \n",
       "Date                                                        \n",
       "2016-12-23  152.801428  167.059998  167.330002  167.600006  \n",
       "2016-12-27  152.949999  166.710007  167.059998  167.330002  \n",
       "2016-12-28  153.077142  167.139999  166.710007  167.059998  \n",
       "2016-12-29  153.242857  166.190002  167.139999  166.710007  \n",
       "2016-12-30  153.197141  166.600006  166.190002  167.139999  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.drop(['ma7', 'Close', 'ma30'],axis=1)\n",
    "df_train['ma7_1'] = df['ma7'].shift(periods = 11, axis=0)\n",
    "df_train['ma7_2'] = df['ma7'].shift(periods = 18, axis=0)\n",
    "df_train['ma7_3'] = df['ma7'].shift(periods = 25, axis=0)\n",
    "df_train['ma7_4'] = df['ma7'].shift(periods = 32, axis=0)\n",
    "df_train['ma30_1'] = df['ma7'].shift(periods = 62, axis=0)\n",
    "df_train['ma30_2'] = df['ma7'].shift(periods = 92, axis=0)\n",
    "df_train['ma30_3'] = df['ma7'].shift(periods = 112, axis=0)\n",
    "df_train['ma30_4'] = df['ma7'].shift(periods = 142, axis=0)\n",
    "df_train['Close_1'] = df['Close'].shift(periods = 1, axis=0)\n",
    "df_train['Close_2'] = df['Close'].shift(periods = 2, axis=0)\n",
    "df_train['Close_3'] = df['Close'].shift(periods = 3, axis=0)\n",
    "print (df_train.shape)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inter_polation_norm(x):\n",
    "    return (x-x.min())/(x.max() - x.min())\n",
    "def z_score_norm(x):\n",
    "    return (x - x.mean())/x.std()\n",
    "df_train = inter_polation_norm(df_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>std30</th>\n",
       "      <th>ma7_1</th>\n",
       "      <th>ma7_2</th>\n",
       "      <th>ma7_3</th>\n",
       "      <th>ma7_4</th>\n",
       "      <th>ma30_1</th>\n",
       "      <th>ma30_2</th>\n",
       "      <th>ma30_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ma7_2_sin4pi</th>\n",
       "      <th>ma7_3_sin4pi</th>\n",
       "      <th>ma7_4_sin4pi</th>\n",
       "      <th>ma30_1_sin4pi</th>\n",
       "      <th>ma30_2_sin4pi</th>\n",
       "      <th>ma30_3_sin4pi</th>\n",
       "      <th>ma30_4_sin4pi</th>\n",
       "      <th>Close_1_sin4pi</th>\n",
       "      <th>Close_2_sin4pi</th>\n",
       "      <th>Close_3_sin4pi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-03-08</th>\n",
       "      <td>0.363031</td>\n",
       "      <td>0.309775</td>\n",
       "      <td>0.304559</td>\n",
       "      <td>0.301043</td>\n",
       "      <td>0.315269</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>0.385282</td>\n",
       "      <td>0.334864</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>0.356117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731275</td>\n",
       "      <td>-0.972315</td>\n",
       "      <td>-0.991664</td>\n",
       "      <td>-0.875485</td>\n",
       "      <td>-0.936130</td>\n",
       "      <td>-0.971979</td>\n",
       "      <td>-0.998682</td>\n",
       "      <td>-0.996346</td>\n",
       "      <td>-0.929146</td>\n",
       "      <td>-0.970890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-08</th>\n",
       "      <td>0.381696</td>\n",
       "      <td>0.314331</td>\n",
       "      <td>0.314743</td>\n",
       "      <td>0.314983</td>\n",
       "      <td>0.304299</td>\n",
       "      <td>0.354060</td>\n",
       "      <td>0.382254</td>\n",
       "      <td>0.334065</td>\n",
       "      <td>0.358859</td>\n",
       "      <td>0.347776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630616</td>\n",
       "      <td>-0.965579</td>\n",
       "      <td>-0.995848</td>\n",
       "      <td>-0.870583</td>\n",
       "      <td>-0.979501</td>\n",
       "      <td>-0.942050</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>-0.998684</td>\n",
       "      <td>-0.996346</td>\n",
       "      <td>-0.929146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-08</th>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.321723</td>\n",
       "      <td>0.325815</td>\n",
       "      <td>0.324238</td>\n",
       "      <td>0.299786</td>\n",
       "      <td>0.349547</td>\n",
       "      <td>0.378284</td>\n",
       "      <td>0.331779</td>\n",
       "      <td>0.375199</td>\n",
       "      <td>0.337492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585609</td>\n",
       "      <td>-0.949282</td>\n",
       "      <td>-0.999149</td>\n",
       "      <td>-0.856097</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>-0.890963</td>\n",
       "      <td>-0.998205</td>\n",
       "      <td>-0.999138</td>\n",
       "      <td>-0.998684</td>\n",
       "      <td>-0.996346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-08</th>\n",
       "      <td>0.379752</td>\n",
       "      <td>0.329906</td>\n",
       "      <td>0.342345</td>\n",
       "      <td>0.332008</td>\n",
       "      <td>0.294759</td>\n",
       "      <td>0.347433</td>\n",
       "      <td>0.371428</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>0.386625</td>\n",
       "      <td>0.324695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533263</td>\n",
       "      <td>-0.940596</td>\n",
       "      <td>-0.998993</td>\n",
       "      <td>-0.798192</td>\n",
       "      <td>-0.989349</td>\n",
       "      <td>-0.806759</td>\n",
       "      <td>-0.994846</td>\n",
       "      <td>-0.997133</td>\n",
       "      <td>-0.999138</td>\n",
       "      <td>-0.998684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-08</th>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.324614</td>\n",
       "      <td>0.361995</td>\n",
       "      <td>0.339378</td>\n",
       "      <td>0.293787</td>\n",
       "      <td>0.341149</td>\n",
       "      <td>0.367658</td>\n",
       "      <td>0.317211</td>\n",
       "      <td>0.392338</td>\n",
       "      <td>0.313498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522899</td>\n",
       "      <td>-0.910879</td>\n",
       "      <td>-0.995746</td>\n",
       "      <td>-0.747705</td>\n",
       "      <td>-0.976359</td>\n",
       "      <td>-0.715915</td>\n",
       "      <td>-0.992607</td>\n",
       "      <td>-0.962130</td>\n",
       "      <td>-0.997133</td>\n",
       "      <td>-0.999138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      DJIA     std30     ma7_1     ma7_2     ma7_3  \\\n",
       "Date                                                                     \n",
       "2000-03-08  0.363031  0.309775  0.304559  0.301043  0.315269  0.356231   \n",
       "2000-04-08  0.381696  0.314331  0.314743  0.314983  0.304299  0.354060   \n",
       "2000-07-08  0.385585  0.321723  0.325815  0.324238  0.299786  0.349547   \n",
       "2000-08-08  0.379752  0.329906  0.342345  0.332008  0.294759  0.347433   \n",
       "2000-09-08  0.400361  0.324614  0.361995  0.339378  0.293787  0.341149   \n",
       "\n",
       "               ma7_4    ma30_1    ma30_2    ma30_3       ...        \\\n",
       "Date                                                     ...         \n",
       "2000-03-08  0.385282  0.334864  0.346405  0.356117       ...         \n",
       "2000-04-08  0.382254  0.334065  0.358859  0.347776       ...         \n",
       "2000-07-08  0.378284  0.331779  0.375199  0.337492       ...         \n",
       "2000-08-08  0.371428  0.323553  0.386625  0.324695       ...         \n",
       "2000-09-08  0.367658  0.317211  0.392338  0.313498       ...         \n",
       "\n",
       "            ma7_2_sin4pi  ma7_3_sin4pi  ma7_4_sin4pi  ma30_1_sin4pi  \\\n",
       "Date                                                                  \n",
       "2000-03-08     -0.731275     -0.972315     -0.991664      -0.875485   \n",
       "2000-04-08     -0.630616     -0.965579     -0.995848      -0.870583   \n",
       "2000-07-08     -0.585609     -0.949282     -0.999149      -0.856097   \n",
       "2000-08-08     -0.533263     -0.940596     -0.998993      -0.798192   \n",
       "2000-09-08     -0.522899     -0.910879     -0.995746      -0.747705   \n",
       "\n",
       "            ma30_2_sin4pi  ma30_3_sin4pi  ma30_4_sin4pi  Close_1_sin4pi  \\\n",
       "Date                                                                      \n",
       "2000-03-08      -0.936130      -0.971979      -0.998682       -0.996346   \n",
       "2000-04-08      -0.979501      -0.942050      -0.999938       -0.998684   \n",
       "2000-07-08      -0.999997      -0.890963      -0.998205       -0.999138   \n",
       "2000-08-08      -0.989349      -0.806759      -0.994846       -0.997133   \n",
       "2000-09-08      -0.976359      -0.715915      -0.992607       -0.962130   \n",
       "\n",
       "            Close_2_sin4pi  Close_3_sin4pi  \n",
       "Date                                        \n",
       "2000-03-08       -0.929146       -0.970890  \n",
       "2000-04-08       -0.996346       -0.929146  \n",
       "2000-07-08       -0.998684       -0.996346  \n",
       "2000-08-08       -0.999138       -0.998684  \n",
       "2000-09-08       -0.997133       -0.999138  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trignometric_expansion(data, k):\n",
    "    l = [data]\n",
    "    cols = data.columns\n",
    "    for j in range(1, k+1):\n",
    "        cos = np.cos(j*math.pi*data)\n",
    "        cos.columns = [(cols[i] + '_cos{0}pi'.format(j)) for i in range(len(cols))]\n",
    "        sin = np.sin(j*math.pi*data)\n",
    "        sin.columns = [(cols[i] + '_sin{0}pi'.format(j)) for i in range(len(cols))]\n",
    "        l.append(cos)\n",
    "        l.append(sin)\n",
    "    output = pd.concat(l, axis=1)\n",
    "    output.dropna(axis=0, how='any', inplace=True)\n",
    "    return output\n",
    "df_train = trignometric_expansion(df_train, 4)\n",
    "df_train.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-03-08</th>\n",
       "      <td>0.379083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-08</th>\n",
       "      <td>0.378305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-08</th>\n",
       "      <td>0.381027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-08</th>\n",
       "      <td>0.396970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-08</th>\n",
       "      <td>0.396192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close\n",
       "Date                \n",
       "2000-03-08  0.379083\n",
       "2000-04-08  0.378305\n",
       "2000-07-08  0.381027\n",
       "2000-08-08  0.396970\n",
       "2000-09-08  0.396192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = df.loc[df_train.index][['Close']]\n",
    "df_target = inter_polation_norm(df_target)\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train test split\n",
    "x_train, y_train = df_train.loc[:'2014-01-01'].as_matrix(), df_target.loc[:'2014-01-01'].as_matrix()\n",
    "x_test, y_test = df_train.loc['2014-01-01':].as_matrix(), df_target.loc['2014-01-01':].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## params\n",
    "N_FEATURES = x_train.shape[1] # number of input features\n",
    "X = tf.placeholder(tf.float32, [None, N_FEATURES])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Tanh:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def new_fc_layer(in_layer, n_input_features, n_output_layer, activation=''):\n",
    "    weights = tf.Variable(tf.truncated_normal([n_input_features, n_output_layer], stddev=0.1))\n",
    "    biases = tf.Variable(tf.constant(value=1, dtype=tf.float32, shape = [n_output_layer]))\n",
    "    out_layer = tf.matmul(in_layer, weights) + biases\n",
    "    activation = activation.lower()\n",
    "    if(activation == 'relu'):\n",
    "        out_layer = tf.nn.relu(out_layer)\n",
    "    elif(activation == 'tanh'):\n",
    "        out_layer = tf.nn.tanh(out_layer)\n",
    "    elif(activation == 'sigmoid'):\n",
    "        out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer, weights, biases\n",
    "## Hidden layer 1\n",
    "N_HIDDEN_L1 = 1\n",
    "hidden_layer_1, weight_1, biases_1 = new_fc_layer(X, N_FEATURES, N_HIDDEN_L1, 'tanh')\n",
    "\n",
    "print (hidden_layer_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 1e-4\n",
    "cost = tf.reduce_mean(tf.square(hidden_layer_1-Y))\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           25000, 0.8, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
    "y_pred = hidden_layer_1\n",
    "y_true = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Cost function and optimization\n",
    "# # BETA = 0.001 #L2 regularization penalty factor\n",
    "# LEARNING_RATE = 1e-3\n",
    "# cost = tf.reduce_mean(tf.square(hidden_layer_1-Y)) # To be added L2 regularization\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "# ## Making Prediction\n",
    "# y_pred = hidden_layer_1\n",
    "# y_true = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.......\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--     0.037841 --     0 --    0.07660 -- \n",
      "-- Making prediction at 0th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "RMSE = 0.2197181286227512\n",
      "MAE = 0.19302750264526045\n",
      "---Running time: 0.04503202438354492 seconds ---\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9fb8c0b36b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAINING_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Making prediction on training set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9fb8c0b36b52>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(train_x, train_y, n_epochs, batch_size, session, saver)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfeed_dict_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mcost_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 30\n",
    "TRAINING_EPOCHS = 20000\n",
    "\n",
    "## Helper function for optimization\n",
    "def optimize(train_x, train_y, n_epochs, batch_size, session, saver):\n",
    "    n_samples = train_x.shape[0]\n",
    "    n_iterations = np.int(np.floor(n_samples/batch_size))+1\n",
    "    start_time = time.time()\n",
    "    cost_history = np.empty(shape=[1],dtype=float)\n",
    "    print (\"Training.......\")\n",
    "        \n",
    "    dir_path = './jagdis_paper_test_2/'\n",
    "    if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "    for epoch in np.arange(n_epochs+1):\n",
    "        for itr in np.arange(n_iterations):\n",
    "            start = (itr * batch_size) % (n_samples - batch_size)\n",
    "            batch_x, batch_y = train_x[start:start + batch_size], train_y[start:start + batch_size]\n",
    "            feed_dict_train = {X: batch_x, Y: batch_y}\n",
    "            _, c = session.run([optimizer, cost], feed_dict=feed_dict_train)\n",
    "            cost_history = np.append(cost_history,c)\n",
    "            \n",
    "        if(epoch % 1000 == 0):\n",
    "            print (\"-- Elapsed time -- Epoch -- Cost value -- \")\n",
    "            print (\"-- {:12.6f} -- {:5d} -- {:10.5f} -- \".format((time.time() - start_time), \n",
    "                                                                                    epoch, \n",
    "                                                                                    c, \n",
    "                                                                                    ))\n",
    "            print (\"-- Making prediction at {}th epoch\".format(epoch))\n",
    "            make_prediction(x_test, y_test, sess, BATCH_SIZE)\n",
    "            plt.savefig('{0}{1}th_epoch'.format(dir_path, epoch), dpi=1000)\n",
    "        \n",
    "#             Draw weights of convolutional layer\n",
    "#             if(epoch % (n_epochs/2) == 0):\n",
    "#                 plot_conv_weights(session, conv_weights[0], 'conv_1', 1, epoch)\n",
    "#                 plot_conv_weights(session, conv_weights[1], 'conv_2', 1, epoch)\n",
    "#                 plot_conv_weights(session, conv_weights[2], 'conv_3', 1, epoch)\n",
    "                  \n",
    "#         Save model in folder rnn_model\n",
    "        \n",
    "#         saver.save(sess, 'rnn_model/new_cnn')\n",
    "        \n",
    "#         print running time and output cost value graph\n",
    "    print (\"---Running time: %s seconds ---\" % (time.time() - start_time))\n",
    "    print ('*'*50)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.clf()\n",
    "    plt.plot(cost_history)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Helper function to print confusion matrix\n",
    "def make_prediction(test_x, test_y, session, batch_size):\n",
    "    print (\"Making prediction.......\")\n",
    "    start_time = time.time()\n",
    "    n_samples = test_x.shape[0]\n",
    "    n_iterations = np.int(np.floor(n_samples/batch_size))+1\n",
    "    pred = np.zeros((n_samples, test_y.shape[1]))\n",
    "    true = np.zeros((n_samples, test_y.shape[1]))\n",
    "    for itr in np.arange(n_iterations):\n",
    "        start = (itr * batch_size) % (n_samples - batch_size)\n",
    "        batch_x, batch_y = test_x[start:start + batch_size], test_y[start:start + batch_size]\n",
    "        feed_dict_test = {X: batch_x, Y: batch_y}\n",
    "        pred[start:start + batch_size], true[start:start + batch_size] = session.run([y_pred, y_true], feed_dict=feed_dict_test)\n",
    "    rmse = math.sqrt(metrics.mean_squared_error(pred, true))\n",
    "    mae = metrics.mean_absolute_error(pred, true)\n",
    "    print(pred.shape)\n",
    "#     pred = pd.Series(pred, index=df_target.loc['2014-01-01':].index)\n",
    "#     true = pd.Series(true, index=df_target.loc['2014-01-01':].index)\n",
    "    print (\"RMSE = {}\".format(rmse))\n",
    "    print (\"MAE = {}\".format(mae))\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df_target.loc['2014-01-01':].index,pred, color = 'r', label='Predicted' )\n",
    "    ax.plot(df_target.loc['2014-01-01':].index, true, color = 'b', label='Actual',sharex=True)\n",
    "    ax.legend(loc='upper right', shadow=True)\n",
    "#     plt.show()\n",
    "    print (\"---Running time: {0} seconds ---\".format((time.time() - start_time)))\n",
    "    print ('*'*50)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    optimize(x_train, y_train, TRAINING_EPOCHS, BATCH_SIZE, sess, saver)\n",
    "    print (\"Making prediction on training set\")\n",
    "    make_prediction(x_train, y_train, sess, BATCH_SIZE)\n",
    "    print (\"Making training prediction on test 1 set\")\n",
    "    make_prediction(x_test, y_test, sess, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
